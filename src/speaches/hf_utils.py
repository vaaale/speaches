from collections.abc import Generator
import logging
from pathlib import Path
import shutil
import time
from typing import TypedDict

import huggingface_hub
from huggingface_hub.constants import HF_HUB_CACHE
from pydantic import BaseModel

logger = logging.getLogger(__name__)

MODEL_CARD_DOESNT_EXISTS_ERROR_MESSAGE = """The model repository does not contain a valid model card. This is likely due to the breaking change introduce v0.8.0 release. You should try to delete the model and re-download it using `DELETE /v1/models/{model_id}` and then `POST /v1/models`. Or if the issue persists, you can try to delete the entire HuggingFace cache directory (delete the whole volume if you are using Docker). Apologies for the inconvenience."""


class HfModelFilterDict(TypedDict):
    filter: list[str] | None
    model_name: str | None


class HfModelFilter(BaseModel):
    model_name: str | None = None
    library_name: str | None = None
    task: str | None = None
    tags: set[str] | None = None

    def passes_filter(self, model_id: str, model_card_data: huggingface_hub.ModelCardData) -> bool:
        if self.model_name is not None:
            if self.model_name.lower() not in model_id.lower():
                logger.debug(f"Model ID '{model_id}' does not match filter model name '{self.model_name}'")
                # allow partial match (case insensitive)
                return False

        # convert None to an empty set so it's easier to work with
        model_card_data_tags = set(model_card_data.tags) if model_card_data.tags is not None else set()
        if self.library_name is not None:
            # Handle both 'library_name' (correct) and 'library' (legacy/incorrect) fields
            model_library = model_card_data.library_name or getattr(model_card_data, "library", None)
            if model_library != self.library_name and self.library_name not in model_card_data_tags:
                logger.debug(
                    f"Model ID '{model_id}' does not match filter library '{self.library_name}': {model_card_data.to_dict()}"
                )
                return False
        if self.task is not None and (
            self.task != model_card_data.pipeline_tag and self.task not in model_card_data_tags
        ):
            logger.debug(f"Model ID '{model_id}' does not match filter task '{self.task}': {model_card_data.to_dict()}")
            return False
        if self.tags is not None and not self.tags.issubset(model_card_data_tags):
            logger.debug(f"Model ID '{model_id}' does not match filter tags '{self.tags}': {model_card_data.to_dict()}")
            return False
        return True

    def list_model_kwargs(self) -> HfModelFilterDict:
        kwargs = {"filter": []}
        if self.library_name is not None:
            kwargs["filter"].append(self.library_name)
        if self.task is not None:
            kwargs["filter"].append(self.task)
        if self.tags is not None and len(self.tags) > 0:
            kwargs["filter"].extend(list(self.tags))
        if self.model_name is not None:
            kwargs["model_name"] = self.model_name  # pyright: ignore[reportArgumentType]

        if len(kwargs["filter"]) == 0:
            kwargs.pop("filter")
        return kwargs  # pyright: ignore[reportReturnType]


def get_cached_model_repos_info() -> list[huggingface_hub.CachedRepoInfo]:
    hf_cache_info = huggingface_hub.scan_cache_dir()
    cache_repos_info = [repo for repo in list(hf_cache_info.repos) if repo.repo_type == "model"]
    return cache_repos_info


def get_model_card_data_from_cached_repo_info(
    cached_repo_info: huggingface_hub.CachedRepoInfo,
) -> huggingface_hub.ModelCardData | None:
    revisions = list(cached_repo_info.revisions)
    # revision = revisions[0] if len(revisions) == 1 else next(rev for rev in revisions if "main" in rev.refs)
    revision = revisions[0] if len(revisions) == 1 else sorted(revisions, key=lambda rev: rev.last_modified)[-1]
    files = list(revision.files)
    readme_cached_file_info = next((f for f in files if f.file_name == "README.md"), None)
    if readme_cached_file_info is None:
        logger.debug(f"Model repo '{cached_repo_info.repo_id}' does not have README.md file in the cache")
        return None
    readme_file_path = readme_cached_file_info.file_path
    model_card = huggingface_hub.ModelCard.load(readme_file_path, repo_type="model")
    assert isinstance(model_card.data, huggingface_hub.ModelCardData)
    return model_card.data


def load_repo_model_card_data(readme_file_path: str | Path) -> huggingface_hub.ModelCardData:
    model_card = huggingface_hub.ModelCard.load(readme_file_path, repo_type="model")
    assert isinstance(model_card.data, huggingface_hub.ModelCardData), model_card
    return model_card.data


def extract_language_list(card_data: huggingface_hub.ModelCardData) -> list[str]:
    assert card_data.language is None or isinstance(card_data.language, str | list)
    if card_data.language is None:
        language = []
    elif isinstance(card_data.language, str):
        language = [card_data.language]
    else:
        # NOTE:I've added `isinstance` check because some models would have non-string values in the list, e.g. https://huggingface.co/jkawamoto/whisper-tiny-ct2 has `False` in the list. AFAICT in the example it's not the metadata that is incorrect but rather `no` language is somehow being represented as `False` instead of `"no"`.
        language = [lang for lang in card_data.language if isinstance(lang, str)]
    return language


def list_local_model_ids() -> list[str]:
    model_dirs = list(Path(HF_HUB_CACHE).glob("models--*"))
    return [model_id_from_path(model_dir) for model_dir in model_dirs]


# alternative implementation that uses `huggingface_hub.scan_cache_dir`. Slightly cleaner but much slower
# def list_local_model_ids() -> list[str]:
#     start = time.perf_counter()
#     hf_cache = huggingface_hub.scan_cache_dir()
#     logger.debug(f"Scanned HuggingFace cache in {time.perf_counter() - start:.2f} seconds")
#     hf_models = [repo for repo in list(hf_cache.repos) if repo.repo_type == "model"]
#     return [model.repo_id for model in hf_models]


def does_local_model_exist(model_id: str) -> bool:
    return model_id in list_local_model_ids()


def model_id_from_path(repo_path: Path) -> str:
    repo_type, repo_id = repo_path.name.split("--", maxsplit=1)
    repo_type = repo_type[:-1]  # "models" -> "model"
    assert repo_type == "model"
    repo_id = repo_id.replace("--", "/")  # google--fleurs -> "google/fleurs"
    return repo_id


def get_model_repo_path(model_id: str, *, cache_dir: str | Path | None = None) -> Path | None:
    if cache_dir is None:
        cache_dir = HF_HUB_CACHE

    cache_dir = Path(cache_dir).expanduser().resolve()
    if not cache_dir.exists():
        raise huggingface_hub.CacheNotFound(
            f"Cache directory not found: {cache_dir}. Please use `cache_dir` argument or set `HF_HUB_CACHE` environment variable.",
            cache_dir=cache_dir,
        )

    if cache_dir.is_file():
        raise ValueError(
            f"Scan cache expects a directory but found a file: {cache_dir}. Please use `cache_dir` argument or set `HF_HUB_CACHE` environment variable."
        )

    for repo_path in cache_dir.iterdir():
        if not repo_path.is_dir():
            continue
        if repo_path.name == ".locks":  # skip './.locks/' folder
            continue
        if "--" not in repo_path.name:  # cache might contain unrelated custom files
            continue
        repo_type, repo_id = repo_path.name.split("--", maxsplit=1)
        repo_type = repo_type[:-1]  # "models" -> "model"
        repo_id = repo_id.replace("--", "/")  # google--fleurs -> "google/fleurs"
        if repo_type != "model":
            continue
        if model_id == repo_id:
            return repo_path

    return None


def list_model_files(
    model_id: str, glob_pattern: str = "**/*", *, cache_dir: str | Path | None = None
) -> Generator[Path]:
    repo_path = get_model_repo_path(model_id, cache_dir=cache_dir)
    if repo_path is None:
        return None
    snapshots_path = repo_path / "snapshots"
    if not snapshots_path.exists():
        return None
    yield from list(snapshots_path.glob(glob_pattern))


def delete_local_model_repo(model_id: str) -> None:
    model_repo_path = get_model_repo_path(model_id)
    if model_repo_path is None:
        raise FileNotFoundError(f"Model repo not found: {model_id}")
    logger.debug(f"Deleting model repo: {model_repo_path}")
    start = time.perf_counter()
    shutil.rmtree(model_repo_path)
    logger.info(f"Deleted '{model_repo_path}' in {time.perf_counter() - start:.2f} seconds")
